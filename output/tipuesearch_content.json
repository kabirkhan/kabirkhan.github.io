{"pages":[{"text":"I am a data scientist and machine learning engineer formally trained as a quantitative political scientist. Currently I am Chief Data Scientist at the Kenyan startup BRCK . Previously, I founded New Knowledge and the data science podcast, Partially Derivative . Prior to New Knowledge, I led Ushahidi's work on crisis and humanitarian data and launched CrisisNET . I was also the Director of the low-resource technology Governance Project at FrontlineSMS . I earned a Ph.D. in Political Science from the University of California, Davis researching the quantitative impact of civil wars on health care systems. I earned a B.A. from the University of Miami, where I triple majored in political science, international studies, and religious studies. Email: cralbon@gmail.com Twitter: @chrisalbon Curriculum Vitae Education Ph.D., Political Science , University of California, Davis. 2012 Dissertation: \"Civil Wars And Health Systems\", a quantitative analysis of the determinants of rebel and government behavior towards health system destruction and reconstruction using original data Fields: International Relations, Quantitative Methodology, and Epidemiology M.A., Political Science , University of California, Davis. 2010 Thesis: \"U.N. Peace Operations And Public Health After Civil War\" B.A. , University of Miami, Miami, FL. 2006 Triple majored in political science, international studies, and religious studies Work Experience Chief Data Scientist , BRCK , 2017 - Present Creator , Machine Learning Flashcards , 2017 - Present Author , Python Machine Learning Cookbook, O'Reilly Media , Forthcoming Co-founder & Co-host , Partially Derivative , 2014 - 2017 Co-founded a podcast on data and data science. Co-founder & Chief Science Officer , New Knowledge , 2015 - 2016 In charge of everything data science and product. Director of CrisisNET , Ushahidi , 2014 - 2015 Launched a pipeline for global humanitarian crisis data. Director of Data Projects , Ushahidi , 2013 - 2014 The non-profit's first data science hire; led all data science efforts. Project Director , FrontlineSMS , 2012 - 2013 Led FrontlineSMS's Governance Project, an effort improve the transparency and accountability of governments through low resource mobile technology Other Experience Moderator , /r/DataScience, Reddit , 2015 - Present Volunteer Data Scientist , DataKind , 2015 Contributor , Daily Dot , 2012 - 2013 Write opinion pieces on the politics of data and the internet Contributor , United Nations Dispatch , 2011 - 2013 Write news, opinion, and analysis on global affairs, particularly relating to health during conflict, global health politics, and the role of social media Blogger , Conflict Health , 2008 - 2012 Designed and launched blog on defending health and health workers against persecution, violence, and armed conflict Wrote 485 posts over four years Cited by major publications including The Atlantic, Harpers, Wired, The Economist, Time, The Guardian, and The American Prospect Contributor , United States Naval Institute Blog , 2009 - 2011 Wrote posts on the U.S. Navy's role in disaster relief, humanitarian assistance, and health diplomacy for one of America's most prestigious professional military associations Research Assistant , U.C. Davis Department Of Political Science , 2008 - 2009 Researched the effect of U.S. defense policy on military suicides Founder , Serve Your World 2002 - 2006 An information site on overseas volunteering","title":"About Chris Albon","tags":"pages","loc":"/pages/about.html","url":"/pages/about.html"},{"text":"Preliminaries # Load libraries import numpy as np from keras.datasets import imdb from keras.preprocessing.text import Tokenizer from keras import models from keras import layers # Set random seed np . random . seed ( 0 ) Load IMDB Movie Review Data # Set the number of features we want number_of_features = 1000 # Load data and target vector from movie review data ( train_data , train_target ), ( test_data , test_target ) = imdb . load_data ( num_words = number_of_features ) # Convert movie review data to a one-hot encoded feature matrix tokenizer = Tokenizer ( num_words = number_of_features ) train_features = tokenizer . sequences_to_matrix ( train_data , mode = 'binary' ) test_features = tokenizer . sequences_to_matrix ( test_data , mode = 'binary' ) Construct Neural Network Architecture With Dropout Layer In Keras, we can implement dropout by added Dropout layers into our network architecture. Each Dropout layer will drop a user-defined hyperparameter of units in the previous layer every batch. Remember in Keras the input layer is assumed to be the first layer and not added using the add . Therefore, if we want to add dropout to the input layer, the layer we add in our is a dropout layer. This layer contains both the proportion of the input layer's units to drop 0.2 and input_shape defining the shape of the observation data. Next, after we add a dropout layer with 0.5 after each of the hidden layers. # Start neural network network = models . Sequential () # Add a dropout layer for input layer network . add ( layers . Dropout ( 0.2 , input_shape = ( number_of_features ,))) # Add fully connected layer with a ReLU activation function network . add ( layers . Dense ( units = 16 , activation = 'relu' )) # Add a dropout layer for previous hidden layer network . add ( layers . Dropout ( 0.5 )) # Add fully connected layer with a ReLU activation function network . add ( layers . Dense ( units = 16 , activation = 'relu' )) # Add a dropout layer for previous hidden layer network . add ( layers . Dropout ( 0.5 )) # Add fully connected layer with a sigmoid activation function network . add ( layers . Dense ( units = 1 , activation = 'sigmoid' )) Compile Neural Network # Compile neural network network . compile ( loss = 'binary_crossentropy' , # Cross-entropy optimizer = 'rmsprop' , # Root Mean Square Propagation metrics = [ 'accuracy' ]) # Accuracy performance metric Train Neural Network # Train neural network history = network . fit ( train_features , # Features train_target , # Target vector epochs = 3 , # Number of epochs verbose = 0 , # No output batch_size = 100 , # Number of observations per batch validation_data = ( test_features , test_target )) # Data for evaluation","title":"Adding Dropout","tags":"Deep Learning - Keras","loc":"/deep-learning-keras/adding_dropout.html","url":"/deep-learning-keras/adding_dropout.html"}]}