{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Title: Adding Dropout    \n",
    "Slug: adding_dropout    \n",
    "Summary: How to add dropout to a neural networking for deep learning in Python.    \n",
    "Date: 2017-09-25 12:00  \n",
    "Category: Deep Learning - Keras  \n",
    "Tags: Basics   \n",
    "Authors: Chris Albon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a alt=\"Dropout\" href=\"https://machinelearningflashcards.com\">\n",
    "    <img src=\"adding_dropout/DropOut_print.png\" class=\"flashcard center-block\">\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load IMDB Movie Review Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the number of features we want\n",
    "number_of_features = 1000\n",
    "\n",
    "# Load data and target vector from movie review data\n",
    "(train_data, train_target), (test_data, test_target) = imdb.load_data(num_words=number_of_features)\n",
    "\n",
    "# Convert movie review data to a one-hot encoded feature matrix\n",
    "tokenizer = Tokenizer(num_words=number_of_features)\n",
    "train_features = tokenizer.sequences_to_matrix(train_data, mode='binary')\n",
    "test_features = tokenizer.sequences_to_matrix(test_data, mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Neural Network Architecture With Dropout Layer\n",
    "\n",
    "In Keras, we can implement dropout by added `Dropout` layers into our network architecture. Each `Dropout` layer will drop a user-defined hyperparameter of units in the previous layer every batch. Remember in Keras the input layer is assumed to be the first layer and not added using the `add`. Therefore, if we want to add dropout to the input layer, the layer we add in our is a dropout layer. This layer contains both the proportion of the input layer's units to drop `0.2` and `input_shape` defining the shape of the observation data. Next, after we add a dropout layer with `0.5` after each of the hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Start neural network\n",
    "network = models.Sequential()\n",
    "\n",
    "# Add a dropout layer for input layer\n",
    "network.add(layers.Dropout(0.2, input_shape=(number_of_features,)))\n",
    "\n",
    "# Add fully connected layer with a ReLU activation function\n",
    "network.add(layers.Dense(units=16, activation='relu'))\n",
    "\n",
    "# Add a dropout layer for previous hidden layer\n",
    "network.add(layers.Dropout(0.5))\n",
    "\n",
    "# Add fully connected layer with a ReLU activation function\n",
    "network.add(layers.Dense(units=16, activation='relu'))\n",
    "\n",
    "# Add a dropout layer for previous hidden layer\n",
    "network.add(layers.Dropout(0.5))\n",
    "\n",
    "# Add fully connected layer with a sigmoid activation function\n",
    "network.add(layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compile neural network\n",
    "network.compile(loss='binary_crossentropy', # Cross-entropy\n",
    "                optimizer='rmsprop', # Root Mean Square Propagation\n",
    "                metrics=['accuracy']) # Accuracy performance metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train neural network\n",
    "history = network.fit(train_features, # Features\n",
    "                      train_target, # Target vector\n",
    "                      epochs=3, # Number of epochs\n",
    "                      verbose=0, # No output\n",
    "                      batch_size=100, # Number of observations per batch\n",
    "                      validation_data=(test_features, test_target)) # Data for evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
