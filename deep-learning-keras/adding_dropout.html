v<!DOCTYPE html>
<html lang="en">

<head>
      <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <meta name="description" content="Data Science, Machine Learning, &amp; Artificial Intelligence Projects">
    <meta name="author" content="Kabir Khan">
    <link rel="icon" href="../favicon.ico">

    <title>Adding Dropout - Deep Learning - Keras</title>

    <!-- JQuery -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script>
        window.jQuery || document.write('<script src="../theme/js/jquery.min.js"><\/script>')
    </script>

    <!-- Bootstrap core CSS -->
    <link rel="stylesheet" href="../theme/css/bootstrap.css" />
    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <link rel="stylesheet" type="text/css" href="../theme/css/ie10-viewport-bug-workaround.css" />
    <!-- Custom styles for this template -->
    <link rel="stylesheet" type="text/css" href="../theme/css/style.css" />
    <link rel="stylesheet" type="text/css" href="../theme/css/notebooks.css" />
    <link href='https://fonts.googleapis.com/css?family=PT+Serif:400,700|Roboto:400,500,700' rel='stylesheet' type='text/css'>

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
     <link href="/feeds/all.rss.xml" type="application/rss+xml" rel="alternate" title="Machine Learning and Artificial Intelligence Full RSS Feed" />         <link href="/feeds/deep-learning-keras.rss.xml" type="application/rss+xml" rel="alternate" title="Machine Learning and Artificial Intelligence Categories RSS Feed" />    

    <meta name="tags" content="Basics" />

    <meta name="google-site-verification" content="7RLmddm4HbzdQLpwH2LH94_vBNmcaMGZSEhmmF5n0NM" />
</head>

<body>

    <div class="navbar navbar-fixed-top">
        <div class="container">
            <div class="navbar-header">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a class="navbar-brand" href="..">Kabir Khan</a>
            </div>
            <div class="navbar-collapse collapse" id="searchbar">

                <ul class="nav navbar-nav navbar-right">
                  <li class="dropdown">
                      <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">ML/AI Notes<span class="caret"></span></a>
                      <ul class="dropdown-menu">                          
                          <li><a href="..#Deep-Learning">Deep Learning</a></li>                          
                      </ul>
                  </li>
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">About<span class="caret"></span></a>
                        <ul class="dropdown-menu">
                            <li><a href="../pages/about.html">About Kabir</a></li>
                            <li><a href="https://github.com/kabirkhan">GitHub</a></li>
                            <!-- <li><a href="https://twitter.com/kabir_khan">Twitter</a></li> -->
                            <li><a href="https://www.linkedin.com/in/kabir-khan-378b87108/">LinkedIn</a></li>
                        </ul>
                    </li>


                    <!--<li class="dropdown">
                        <a href="../feeds/blog.rss.xml">Blog RSS</a>
                    </li>-->


                </ul>

                <form class="navbar-form" action="../search.html" onsubmit="return validateForm(this.elements['q'].value);">
                    <div class="form-group" style="display:inline;">
                        <div class="input-group" style="display:table;">
                            <span class="input-group-addon" style="width:1%;"><span class="glyphicon glyphicon-search"></span></span>
                            <input class="form-control search-query" name="q" id="tipue_search_input" placeholder="e.g. scikit KNN, pandas merge" required autocomplete="off" type="text">
                        </div>
                    </div>
                </form>

            </div>
            <!--/.nav-collapse -->
        </div>
    </div>



    <!-- end of header section -->
    <div class="container">
<div class="alert alert-warning advert" role="alert">
    Want to learn machine learning? Use my <a href="https://machinelearningflashcards.com" class="alert-link">machine learning flashcards</a>.
</div>

<section id="content" class="body">
    <header>
    <h1>
      Adding Dropout
    </h1>
<ol class="breadcrumb">
    <li>
        <time class="published" datetime="2017-09-25T12:00:00-07:00">
            25 September 2017
        </time>
    </li>
    <li>Deep Learning - Keras</li>
    <li>Basics</li>
</ol>
</header>
<div class='article_content'>
<h1>What is Dropout?</h1>
<p>Dropout is a state-of-the-art regularization technique for deep neural networks. It is a mask over a particular layer of a network to remove certain nodes and their connections from a training pass.</p>
<h3><strong>e.g.</strong></h3>
<p>If you apply dropout with a probability of 0.2 to a layer, then for each node in that layer there is 0.2 chance of removing it from training. </p>
<p>For each iteration, a different subset of your network is trained creating an ensemble effect. This technique is shown to reduce overfitting and is used in most network architectures today.</p>
<p><img src="http://cs231n.github.io/assets/nn2/dropout.jpeg"></p>
<blockquote>
<p>Image Source: http://cs231n.github.io/neural-networks-2/#reg</p>
</blockquote>
<h2>Packages</h2>
<div class="codehilite"><pre><span></span><span class="c1"># Load libraries</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">keras.datasets</span> <span class="kn">import</span> <span class="n">imdb</span>
<span class="kn">from</span> <span class="nn">keras.preprocessing.text</span> <span class="kn">import</span> <span class="n">Tokenizer</span>
<span class="kn">from</span> <span class="nn">keras</span> <span class="kn">import</span> <span class="n">models</span>
<span class="kn">from</span> <span class="nn">keras</span> <span class="kn">import</span> <span class="n">layers</span>

<span class="c1"># Set random seed</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</pre></div>


<div class="codehilite"><pre><span></span>Using TensorFlow backend.
</pre></div>


<h2>Load IMDB Movie Review Data</h2>
<div class="codehilite"><pre><span></span><span class="c1"># Set the number of features we want</span>
<span class="n">number_of_features</span> <span class="o">=</span> <span class="mi">1000</span>

<span class="c1"># Load data and target vector from movie review data</span>
<span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">train_target</span><span class="p">),</span> <span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">test_target</span><span class="p">)</span> <span class="o">=</span> <span class="n">imdb</span><span class="o">.</span><span class="n">load_data</span><span class="p">(</span><span class="n">num_words</span><span class="o">=</span><span class="n">number_of_features</span><span class="p">)</span>

<span class="c1"># Convert movie review data to a one-hot encoded feature matrix</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">(</span><span class="n">num_words</span><span class="o">=</span><span class="n">number_of_features</span><span class="p">)</span>
<span class="n">train_features</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">sequences_to_matrix</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;binary&#39;</span><span class="p">)</span>
<span class="n">test_features</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">sequences_to_matrix</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;binary&#39;</span><span class="p">)</span>
</pre></div>


<div class="codehilite"><pre><span></span>Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz
17465344/17464789 [==============================] - 36s 2us/step
</pre></div>


<h2>Functions to train and evaluate model</h2>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">train_and_evaluate</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
    <span class="c1"># Compile neural network</span>
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span> <span class="c1"># Cross-entropy</span>
                <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span> <span class="c1"># Adam Optimizer</span>
                <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span> <span class="c1"># Accuracy performance metric</span>

    <span class="c1"># Train neural network</span>
    <span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_features</span><span class="p">,</span> <span class="c1"># Features</span>
                      <span class="n">train_target</span><span class="p">,</span> <span class="c1"># Target vector</span>
                      <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="c1"># Number of epochs</span>
                      <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="c1"># No output</span>
                      <span class="n">batch_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="c1"># Number of observations per batch</span>
                      <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">test_features</span><span class="p">,</span> <span class="n">test_target</span><span class="p">))</span> <span class="c1"># Data for evaluation</span>

    <span class="k">return</span> <span class="n">history</span>
</pre></div>


<h2>Neural Network Architecture</h2>
<p>We'll start with a standard network architecture that doesn't use Dropout</p>
<div class="codehilite"><pre><span></span><span class="c1"># Start neural network</span>
<span class="n">network</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>

<span class="c1"># Add fully connected layer with a ReLU activation function for input layer</span>
<span class="n">network</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="n">number_of_features</span><span class="p">,)))</span>

<span class="c1"># Add fully connected layer with a ReLU activation function</span>
<span class="n">network</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>

<span class="c1"># Add fully connected layer with a sigmoid activation function</span>
<span class="n">network</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">))</span>
</pre></div>


<div class="codehilite"><pre><span></span><span class="n">train_and_evaluate</span><span class="p">(</span><span class="n">network</span><span class="p">)</span>
</pre></div>


<div class="codehilite"><pre><span></span>Train on 25000 samples, validate on 25000 samples
Epoch 1/10
25000/25000 [==============================] - 2s 62us/step - loss: 0.4306 - acc: 0.7998 - val_loss: 0.3347 - val_acc: 0.8580
Epoch 2/10
25000/25000 [==============================] - 1s 42us/step - loss: 0.3220 - acc: 0.8655 - val_loss: 0.3288 - val_acc: 0.8596
Epoch 3/10
25000/25000 [==============================] - 1s 44us/step - loss: 0.3100 - acc: 0.8716 - val_loss: 0.3346 - val_acc: 0.8578
Epoch 4/10
25000/25000 [==============================] - 1s 45us/step - loss: 0.3020 - acc: 0.8742 - val_loss: 0.3273 - val_acc: 0.8596
Epoch 5/10
25000/25000 [==============================] - 1s 42us/step - loss: 0.2910 - acc: 0.8778 - val_loss: 0.3318 - val_acc: 0.8575
Epoch 6/10
25000/25000 [==============================] - 1s 45us/step - loss: 0.2773 - acc: 0.8852 - val_loss: 0.3311 - val_acc: 0.8572
Epoch 7/10
25000/25000 [==============================] - 1s 45us/step - loss: 0.2638 - acc: 0.8940 - val_loss: 0.3382 - val_acc: 0.8552
Epoch 8/10
25000/25000 [==============================] - 1s 45us/step - loss: 0.2482 - acc: 0.8985 - val_loss: 0.3533 - val_acc: 0.8511
Epoch 9/10
25000/25000 [==============================] - 1s 59us/step - loss: 0.2325 - acc: 0.9069 - val_loss: 0.3646 - val_acc: 0.8490
Epoch 10/10
25000/25000 [==============================] - 1s 45us/step - loss: 0.2140 - acc: 0.9160 - val_loss: 0.3940 - val_acc: 0.8450





&lt;keras.callbacks.History at 0x11643df98&gt;
</pre></div>


<h2>Neural Network Architecture With Dropout</h2>
<p>In Keras, we can implement dropout using the convenient <code>Dropout</code> layer into our network architecture. Each <code>Dropout</code> layer will drop a user-defined hyperparameter of units in the previous layer every batch. </p>
<p>Remember in Keras the input layer is assumed to be the first layer and not added using the <code>add</code> method. Therefore, if we want to add dropout to the input layer, the layer we add in our model is a dropout layer. This layer contains both the proportion of the input layer's units to drop <code>0.2</code> and <code>input_shape</code> defining the shape of the observation data. We add <code>Dropout</code> layers with <code>0.5</code> to each subsequent layer.</p>
<div class="codehilite"><pre><span></span><span class="c1"># Start neural network with dropout</span>
<span class="n">network_dropout</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>

<span class="c1"># Add a dropout layer for input layer</span>
<span class="n">network_dropout</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="n">number_of_features</span><span class="p">,)))</span>

<span class="c1"># Add fully connected layer with a ReLU activation function</span>
<span class="n">network_dropout</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>

<span class="c1"># Add a dropout layer for previous hidden layer</span>
<span class="n">network_dropout</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">))</span>

<span class="c1"># Add fully connected layer with a ReLU activation function</span>
<span class="n">network_dropout</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>

<span class="c1"># Add a dropout layer for previous hidden layer</span>
<span class="n">network_dropout</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">))</span>

<span class="c1"># Add fully connected layer with a sigmoid activation function</span>
<span class="n">network_dropout</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">))</span>
</pre></div>


<div class="codehilite"><pre><span></span><span class="n">train_and_evaluate</span><span class="p">(</span><span class="n">network_dropout</span><span class="p">)</span>
</pre></div>


<div class="codehilite"><pre><span></span>Train on 25000 samples, validate on 25000 samples
Epoch 1/10
25000/25000 [==============================] - 2s 78us/step - loss: 0.6368 - acc: 0.6172 - val_loss: 0.4679 - val_acc: 0.8290
Epoch 2/10
25000/25000 [==============================] - 1s 54us/step - loss: 0.4896 - acc: 0.7714 - val_loss: 0.3674 - val_acc: 0.8484
Epoch 3/10
25000/25000 [==============================] - 2s 63us/step - loss: 0.4348 - acc: 0.8100 - val_loss: 0.3393 - val_acc: 0.8579
Epoch 4/10
25000/25000 [==============================] - 2s 71us/step - loss: 0.4130 - acc: 0.8181 - val_loss: 0.3261 - val_acc: 0.8603
Epoch 5/10
25000/25000 [==============================] - 1s 57us/step - loss: 0.4034 - acc: 0.8222 - val_loss: 0.3214 - val_acc: 0.8623
Epoch 6/10
25000/25000 [==============================] - 2s 83us/step - loss: 0.3980 - acc: 0.8232 - val_loss: 0.3262 - val_acc: 0.8612
Epoch 7/10
25000/25000 [==============================] - 1s 56us/step - loss: 0.3926 - acc: 0.8284 - val_loss: 0.3220 - val_acc: 0.8607
Epoch 8/10
25000/25000 [==============================] - 1s 54us/step - loss: 0.3889 - acc: 0.8263 - val_loss: 0.3233 - val_acc: 0.8588
Epoch 9/10
25000/25000 [==============================] - 1s 56us/step - loss: 0.3814 - acc: 0.8350 - val_loss: 0.3216 - val_acc: 0.8584
Epoch 10/10
25000/25000 [==============================] - 2s 66us/step - loss: 0.3804 - acc: 0.8323 - val_loss: 0.3209 - val_acc: 0.8604





&lt;keras.callbacks.History at 0x1170d7fd0&gt;
</pre></div>


<h2>Results</h2>
<p>We can see that without dropout we'll get a much higher training accuracy over 10 epochs. However, our validation accuracy starts to decline. With dropout, our network's training accuracy regularizes and we have a consistently higher validation accuracy.</p>
<h3>Network: 84.5% validation accuracy</h3>
<h3>Network with Dropout: 86.04% validation accuracy</h3>
<p><strong>Expected Output of Confusion Matrix (Percentages)</strong>:
    <table>
    "    <tr>
    "        <td></td>
    "        <th> <strong>Predicted user stayed in the course</strong> </th>
    "        <th> <strong>Predicted user dropped out of the course</strong> </th>
    "    </tr>
    "    <tr>
    "        <td> <strong>User stayed in the course</strong> </td>
    "        <td> TN - 68% </td>
            <td> FP - 9% </td>
        </tr>
    </table></p>
</div>
    <aside>
    <div class="bug-reporting__panel">
        <h3>Find an error or bug?</h3>
        <p>Everything on this site is available on GitHub. Head to <a href='https://github.com/chrisalbon/notes_on_data_science_machine_learning_and_artificial_intelligence/issues/new'>and submit a suggested change</a>. You can also message me directly on <a href='https://twitter.com/chrisalbon'>Twitter</a>.</p>
    </div>
    </aside>
</section>

    </div>
    <!-- start of footer section -->
    <footer class="footer">
        <div class="container">
            <p class="text-muted">
                <center>This project contains 1 pages and is available on <a href="https://github.com/kabirkhan/mlai">GitHub</a>.
                <br/>
                Copyright &copy; Kabir Khan,
                    <time datetime="2017">2017</time>.
                </center>
            </p>
        </div>
    </footer>

    <!-- This jQuery line finds any span that contains code highlighting classes and then selects the parent <pre> tag and adds a border. This is done as a workaround to visually distinguish the code inputs and outputs -->
    <script>
        $( ".hll, .n, .c, .err, .k, .o, .cm, .cp, .c1, .cs, .gd, .ge, .gr, .gh, .gi, .go, .gp, .gs, .gu, .gt, .kc, .kd, .kn, .kp, .kr, .kt, .m, .s, .na, .nb, .nc, .no, .nd, .ni, .ne, .nf, .nl, .nn, .nt, .nv, .ow, .w, .mf, .mh, .mi, .mo, .sb, .sc, .sd, .s2, .se, .sh, .si, .sx, .sr, .s1, .ss, .bp, .vc, .vg, .vi, .il" ).parent( "pre" ).css( "border", "1px solid #DEDEDE" );
    </script>

    <!-- Load Google Analytics -->
    <script>
        (function(i, s, o, g, r, a, m) {
            i['GoogleAnalyticsObject'] = r;
            i[r] = i[r] || function() {
                (i[r].q = i[r].q || []).push(arguments)
            }, i[r].l = 1 * new Date();
            a = s.createElement(o),
                m = s.getElementsByTagName(o)[0];
            a.async = 1;
            a.src = g;
            m.parentNode.insertBefore(a, m)
        })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');

        ga('create', 'UA-111393904-1', 'auto');
        ga('send', 'pageview');
    </script>
    <!-- End of Google Analytics -->

    <!-- Bootstrap core JavaScript
      ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../theme/js/bootstrap.min.js"></script>
    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <script src="../theme/js/ie10-viewport-bug-workaround.js"></script>
    <!-- Amazon OneLink -->
    <script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&adInstanceId=946c0716-c88a-4df0-8944-a058be8c1e86"></script>

</body>

</html>